{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "GAN embedding.ipynb",
      "provenance": [],
      "toc_visible": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "code",
      "metadata": {
        "id": "fK6hlzswo6yW"
      },
      "source": [
        "import os\n",
        "import argparse\n",
        "import numpy as np\n",
        "from PIL import Image\n",
        "from tqdm import tqdm\n",
        "\n",
        "import torch\n",
        "import torch.nn as nn\n",
        "import torch.nn.functional as F\n",
        "import torchvision.transforms as transforms"
      ],
      "execution_count": 1,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "UlzW0uEK-eip"
      },
      "source": [
        "##Mounting your google drive containing the code files.\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "pjtEYwLX-eiq",
        "outputId": "5f0e1cb5-96d0-4fdc-f207-5bfbd20b75a5"
      },
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive')\n",
        "%cd /content/drive/My\\ Drive/"
      ],
      "execution_count": 1,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Mounted at /content/drive\n",
            "/content/drive/My Drive\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "xQBRWwRux2Dr",
        "outputId": "547ccc4e-8ebc-41d7-e756-1953833796ae"
      },
      "source": [
        "!git clone https://github.com/pacifinapacific/StyleGAN_LatentEditor.git\n"
      ],
      "execution_count": 5,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Cloning into 'StyleGAN_LatentEditor'...\n",
            "remote: Enumerating objects: 170, done.\u001b[K\n",
            "remote: Counting objects: 100% (3/3), done.\u001b[K\n",
            "remote: Compressing objects: 100% (3/3), done.\u001b[K\n",
            "remote: Total 170 (delta 0), reused 1 (delta 0), pack-reused 167\u001b[K\n",
            "Receiving objects: 100% (170/170), 4.26 MiB | 3.50 MiB/s, done.\n",
            "Resolving deltas: 100% (70/70), done.\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "YQ_jO7jmx2Af",
        "outputId": "866a58a7-852e-4290-d636-5685d84226d0"
      },
      "source": [
        "cd /content/drive/My Drive/StyleGAN_LatentEditor//"
      ],
      "execution_count": 6,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "/content/drive/My Drive/StyleGAN_LatentEditor\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "aPhbLbDuhwyY",
        "outputId": "4e074dc3-2a74-49b5-89b6-94b6f9a9e195"
      },
      "source": [
        "%ls"
      ],
      "execution_count": 5,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "align_images.py     landmarks_detector.py  \u001b[0m\u001b[01;34msave_image\u001b[0m/\n",
            "\u001b[01;34mdnnlib\u001b[0m/             \u001b[01;34mlatent_W\u001b[0m/              semantic_edit.py\n",
            "encode_image.py     make_morphgif.py       \u001b[01;34msource_image\u001b[0m/\n",
            "face_alignment.py   perceptual_model.py    StyleGAN_editor.ipynb\n",
            "facial_exchange.py  \u001b[01;34m__pycache__\u001b[0m/           stylegan_layers.py\n",
            "image_crossover.py  read_image.py          weight_convert.py\n",
            "image_morphing.py   README.txt             \u001b[01;34mweight_files\u001b[0m/\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 36
        },
        "id": "gG3zVsiP29T5",
        "outputId": "76333d66-862f-466d-f55d-65b16a9a778d"
      },
      "source": [
        "%pwd"
      ],
      "execution_count": 4,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            },
            "text/plain": [
              "'/content/drive/My Drive/StyleGAN_LatentEditor'"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 4
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "X49nUM651Hou"
      },
      "source": [
        "# Download the official StyleGAN trained model from \n",
        "https://drive.google.com/uc?id=1MEGjdvVpUsu1jB4zrXZN7Y4kBBOzizDQ "
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "tvFyck1D0oQv"
      },
      "source": [
        "cp /content/drive/MyDrive/Colab\\ Notebooks/*.pkl /content/drive/MyDrive/StyleGAN_LatentEditor/weight_files/tensorflow/"
      ],
      "execution_count": 7,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 138
        },
        "id": "eWajQJ4Ox1-L",
        "outputId": "a21f6855-dee0-4056-cd09-dae4760975a6"
      },
      "source": [
        "from google.colab import files　#upload \n",
        "files.upload()\n"
      ],
      "execution_count": 3,
      "outputs": [
        {
          "output_type": "error",
          "ename": "SyntaxError",
          "evalue": "ignored",
          "traceback": [
            "\u001b[0;36m  File \u001b[0;32m\"<ipython-input-3-91fce7f87ecf>\"\u001b[0;36m, line \u001b[0;32m1\u001b[0m\n\u001b[0;31m    https://drive.google.com/uc?id=1MEGjdvVpUsu1jB4zrXZN7Y4kBBOzizDQ\u001b[0m\n\u001b[0m           ^\u001b[0m\n\u001b[0;31mSyntaxError\u001b[0m\u001b[0;31m:\u001b[0m invalid syntax\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "8fB4WMXA3yNd",
        "outputId": "d4496b70-88ee-49fe-92cb-fdf85f5d51c8"
      },
      "source": [
        "!pip install tensorflow==1.14.0\n",
        "import tensorflow as tf\n",
        "print(tf.__version__)"
      ],
      "execution_count": 8,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Collecting tensorflow==1.14.0\n",
            "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/f4/28/96efba1a516cdacc2e2d6d081f699c001d414cc8ca3250e6d59ae657eb2b/tensorflow-1.14.0-cp37-cp37m-manylinux1_x86_64.whl (109.3MB)\n",
            "\u001b[K     |████████████████████████████████| 109.3MB 58kB/s \n",
            "\u001b[?25hRequirement already satisfied: google-pasta>=0.1.6 in /usr/local/lib/python3.7/dist-packages (from tensorflow==1.14.0) (0.2.0)\n",
            "Collecting keras-applications>=1.0.6\n",
            "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/71/e3/19762fdfc62877ae9102edf6342d71b28fbfd9dea3d2f96a882ce099b03f/Keras_Applications-1.0.8-py3-none-any.whl (50kB)\n",
            "\u001b[K     |████████████████████████████████| 51kB 6.7MB/s \n",
            "\u001b[?25hRequirement already satisfied: keras-preprocessing>=1.0.5 in /usr/local/lib/python3.7/dist-packages (from tensorflow==1.14.0) (1.1.2)\n",
            "Requirement already satisfied: termcolor>=1.1.0 in /usr/local/lib/python3.7/dist-packages (from tensorflow==1.14.0) (1.1.0)\n",
            "Requirement already satisfied: protobuf>=3.6.1 in /usr/local/lib/python3.7/dist-packages (from tensorflow==1.14.0) (3.12.4)\n",
            "Requirement already satisfied: gast>=0.2.0 in /usr/local/lib/python3.7/dist-packages (from tensorflow==1.14.0) (0.4.0)\n",
            "Collecting tensorboard<1.15.0,>=1.14.0\n",
            "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/91/2d/2ed263449a078cd9c8a9ba50ebd50123adf1f8cfbea1492f9084169b89d9/tensorboard-1.14.0-py3-none-any.whl (3.1MB)\n",
            "\u001b[K     |████████████████████████████████| 3.2MB 33.7MB/s \n",
            "\u001b[?25hRequirement already satisfied: wheel>=0.26 in /usr/local/lib/python3.7/dist-packages (from tensorflow==1.14.0) (0.36.2)\n",
            "Requirement already satisfied: six>=1.10.0 in /usr/local/lib/python3.7/dist-packages (from tensorflow==1.14.0) (1.15.0)\n",
            "Requirement already satisfied: astor>=0.6.0 in /usr/local/lib/python3.7/dist-packages (from tensorflow==1.14.0) (0.8.1)\n",
            "Requirement already satisfied: numpy<2.0,>=1.14.5 in /usr/local/lib/python3.7/dist-packages (from tensorflow==1.14.0) (1.19.5)\n",
            "Requirement already satisfied: absl-py>=0.7.0 in /usr/local/lib/python3.7/dist-packages (from tensorflow==1.14.0) (0.12.0)\n",
            "Requirement already satisfied: wrapt>=1.11.1 in /usr/local/lib/python3.7/dist-packages (from tensorflow==1.14.0) (1.12.1)\n",
            "Requirement already satisfied: grpcio>=1.8.6 in /usr/local/lib/python3.7/dist-packages (from tensorflow==1.14.0) (1.34.1)\n",
            "Collecting tensorflow-estimator<1.15.0rc0,>=1.14.0rc0\n",
            "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/3c/d5/21860a5b11caf0678fbc8319341b0ae21a07156911132e0e71bffed0510d/tensorflow_estimator-1.14.0-py2.py3-none-any.whl (488kB)\n",
            "\u001b[K     |████████████████████████████████| 491kB 29.1MB/s \n",
            "\u001b[?25hRequirement already satisfied: h5py in /usr/local/lib/python3.7/dist-packages (from keras-applications>=1.0.6->tensorflow==1.14.0) (3.1.0)\n",
            "Requirement already satisfied: setuptools in /usr/local/lib/python3.7/dist-packages (from protobuf>=3.6.1->tensorflow==1.14.0) (57.0.0)\n",
            "Requirement already satisfied: werkzeug>=0.11.15 in /usr/local/lib/python3.7/dist-packages (from tensorboard<1.15.0,>=1.14.0->tensorflow==1.14.0) (1.0.1)\n",
            "Requirement already satisfied: markdown>=2.6.8 in /usr/local/lib/python3.7/dist-packages (from tensorboard<1.15.0,>=1.14.0->tensorflow==1.14.0) (3.3.4)\n",
            "Requirement already satisfied: cached-property; python_version < \"3.8\" in /usr/local/lib/python3.7/dist-packages (from h5py->keras-applications>=1.0.6->tensorflow==1.14.0) (1.5.2)\n",
            "Requirement already satisfied: importlib-metadata; python_version < \"3.8\" in /usr/local/lib/python3.7/dist-packages (from markdown>=2.6.8->tensorboard<1.15.0,>=1.14.0->tensorflow==1.14.0) (4.0.1)\n",
            "Requirement already satisfied: typing-extensions>=3.6.4; python_version < \"3.8\" in /usr/local/lib/python3.7/dist-packages (from importlib-metadata; python_version < \"3.8\"->markdown>=2.6.8->tensorboard<1.15.0,>=1.14.0->tensorflow==1.14.0) (3.7.4.3)\n",
            "Requirement already satisfied: zipp>=0.5 in /usr/local/lib/python3.7/dist-packages (from importlib-metadata; python_version < \"3.8\"->markdown>=2.6.8->tensorboard<1.15.0,>=1.14.0->tensorflow==1.14.0) (3.4.1)\n",
            "\u001b[31mERROR: kapre 0.3.5 has requirement tensorflow>=2.0.0, but you'll have tensorflow 1.14.0 which is incompatible.\u001b[0m\n",
            "Installing collected packages: keras-applications, tensorboard, tensorflow-estimator, tensorflow\n",
            "  Found existing installation: tensorboard 2.5.0\n",
            "    Uninstalling tensorboard-2.5.0:\n",
            "      Successfully uninstalled tensorboard-2.5.0\n",
            "  Found existing installation: tensorflow-estimator 2.5.0\n",
            "    Uninstalling tensorflow-estimator-2.5.0:\n",
            "      Successfully uninstalled tensorflow-estimator-2.5.0\n",
            "  Found existing installation: tensorflow 2.5.0\n",
            "    Uninstalling tensorflow-2.5.0:\n",
            "      Successfully uninstalled tensorflow-2.5.0\n",
            "Successfully installed keras-applications-1.0.8 tensorboard-1.14.0 tensorflow-1.14.0 tensorflow-estimator-1.14.0\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/tensorflow/python/framework/dtypes.py:516: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
            "  _np_qint8 = np.dtype([(\"qint8\", np.int8, 1)])\n",
            "/usr/local/lib/python3.7/dist-packages/tensorflow/python/framework/dtypes.py:517: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
            "  _np_quint8 = np.dtype([(\"quint8\", np.uint8, 1)])\n",
            "/usr/local/lib/python3.7/dist-packages/tensorflow/python/framework/dtypes.py:518: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
            "  _np_qint16 = np.dtype([(\"qint16\", np.int16, 1)])\n",
            "/usr/local/lib/python3.7/dist-packages/tensorflow/python/framework/dtypes.py:519: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
            "  _np_quint16 = np.dtype([(\"quint16\", np.uint16, 1)])\n",
            "/usr/local/lib/python3.7/dist-packages/tensorflow/python/framework/dtypes.py:520: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
            "  _np_qint32 = np.dtype([(\"qint32\", np.int32, 1)])\n",
            "/usr/local/lib/python3.7/dist-packages/tensorflow/python/framework/dtypes.py:525: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
            "  np_resource = np.dtype([(\"resource\", np.ubyte, 1)])\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "1.14.0\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/tensorboard/compat/tensorflow_stub/dtypes.py:541: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
            "  _np_qint8 = np.dtype([(\"qint8\", np.int8, 1)])\n",
            "/usr/local/lib/python3.7/dist-packages/tensorboard/compat/tensorflow_stub/dtypes.py:542: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
            "  _np_quint8 = np.dtype([(\"quint8\", np.uint8, 1)])\n",
            "/usr/local/lib/python3.7/dist-packages/tensorboard/compat/tensorflow_stub/dtypes.py:543: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
            "  _np_qint16 = np.dtype([(\"qint16\", np.int16, 1)])\n",
            "/usr/local/lib/python3.7/dist-packages/tensorboard/compat/tensorflow_stub/dtypes.py:544: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
            "  _np_quint16 = np.dtype([(\"quint16\", np.uint16, 1)])\n",
            "/usr/local/lib/python3.7/dist-packages/tensorboard/compat/tensorflow_stub/dtypes.py:545: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
            "  _np_qint32 = np.dtype([(\"qint32\", np.int32, 1)])\n",
            "/usr/local/lib/python3.7/dist-packages/tensorboard/compat/tensorflow_stub/dtypes.py:550: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
            "  np_resource = np.dtype([(\"resource\", np.ubyte, 1)])\n"
          ],
          "name": "stderr"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "I1E33Isyx10t",
        "outputId": "c7240225-014c-4333-8635-a2e355c642f7"
      },
      "source": [
        "!python weight_convert.py"
      ],
      "execution_count": 18,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/tensorflow/python/framework/dtypes.py:516: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
            "  _np_qint8 = np.dtype([(\"qint8\", np.int8, 1)])\n",
            "/usr/local/lib/python3.7/dist-packages/tensorflow/python/framework/dtypes.py:517: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
            "  _np_quint8 = np.dtype([(\"quint8\", np.uint8, 1)])\n",
            "/usr/local/lib/python3.7/dist-packages/tensorflow/python/framework/dtypes.py:518: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
            "  _np_qint16 = np.dtype([(\"qint16\", np.int16, 1)])\n",
            "/usr/local/lib/python3.7/dist-packages/tensorflow/python/framework/dtypes.py:519: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
            "  _np_quint16 = np.dtype([(\"quint16\", np.uint16, 1)])\n",
            "/usr/local/lib/python3.7/dist-packages/tensorflow/python/framework/dtypes.py:520: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
            "  _np_qint32 = np.dtype([(\"qint32\", np.int32, 1)])\n",
            "/usr/local/lib/python3.7/dist-packages/tensorflow/python/framework/dtypes.py:525: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
            "  np_resource = np.dtype([(\"resource\", np.ubyte, 1)])\n",
            "/usr/local/lib/python3.7/dist-packages/tensorboard/compat/tensorflow_stub/dtypes.py:541: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
            "  _np_qint8 = np.dtype([(\"qint8\", np.int8, 1)])\n",
            "/usr/local/lib/python3.7/dist-packages/tensorboard/compat/tensorflow_stub/dtypes.py:542: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
            "  _np_quint8 = np.dtype([(\"quint8\", np.uint8, 1)])\n",
            "/usr/local/lib/python3.7/dist-packages/tensorboard/compat/tensorflow_stub/dtypes.py:543: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
            "  _np_qint16 = np.dtype([(\"qint16\", np.int16, 1)])\n",
            "/usr/local/lib/python3.7/dist-packages/tensorboard/compat/tensorflow_stub/dtypes.py:544: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
            "  _np_quint16 = np.dtype([(\"quint16\", np.uint16, 1)])\n",
            "/usr/local/lib/python3.7/dist-packages/tensorboard/compat/tensorflow_stub/dtypes.py:545: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
            "  _np_qint32 = np.dtype([(\"qint32\", np.int32, 1)])\n",
            "/usr/local/lib/python3.7/dist-packages/tensorboard/compat/tensorflow_stub/dtypes.py:550: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
            "  np_resource = np.dtype([(\"resource\", np.ubyte, 1)])\n",
            "WARNING:tensorflow:From /content/drive/MyDrive/StyleGAN_LatentEditor/dnnlib/tflib/tfutil.py:34: The name tf.Dimension is deprecated. Please use tf.compat.v1.Dimension instead.\n",
            "\n",
            "WARNING:tensorflow:From /content/drive/MyDrive/StyleGAN_LatentEditor/dnnlib/tflib/tfutil.py:74: The name tf.variable_scope is deprecated. Please use tf.compat.v1.variable_scope instead.\n",
            "\n",
            "WARNING:tensorflow:From /content/drive/MyDrive/StyleGAN_LatentEditor/dnnlib/tflib/tfutil.py:128: The name tf.Session is deprecated. Please use tf.compat.v1.Session instead.\n",
            "\n",
            "WARNING:tensorflow:From /content/drive/MyDrive/StyleGAN_LatentEditor/dnnlib/tflib/tfutil.py:97: The name tf.get_default_session is deprecated. Please use tf.compat.v1.get_default_session instead.\n",
            "\n",
            "WARNING:tensorflow:From /content/drive/MyDrive/StyleGAN_LatentEditor/dnnlib/tflib/tfutil.py:109: The name tf.set_random_seed is deprecated. Please use tf.compat.v1.set_random_seed instead.\n",
            "\n",
            "2021-06-08 07:32:06.043105: W tensorflow/compiler/jit/mark_for_compilation_pass.cc:1412] (One-time warning): Not using XLA:CPU for cluster because envvar TF_XLA_FLAGS=--tf_xla_cpu_global_jit was not set.  If you want XLA:CPU, either set that envvar, or use experimental_jit_scope to enable XLA:CPU.  To confirm that XLA is active, pass --vmodule=xla_compilation_cache=1 (as a proper command-line flag, not via TF_XLA_FLAGS) or set the envvar XLA_FLAGS=--xla_hlo_profile.\n",
            "WARNING:tensorflow:From <string>:364: add_dispatch_support.<locals>.wrapper (from tensorflow.python.ops.array_ops) is deprecated and will be removed in a future version.\n",
            "Instructions for updating:\n",
            "Use tf.where in 2.0, which has the same broadcast rule as np.where\n",
            "sd only g_synthesis.blocks.8x8.conv0_up.intermediate.kernel torch.Size([1, 1, 3, 3])\n",
            "sd only g_synthesis.blocks.16x16.conv0_up.intermediate.kernel torch.Size([1, 1, 3, 3])\n",
            "sd only g_synthesis.blocks.32x32.conv0_up.intermediate.kernel torch.Size([1, 1, 3, 3])\n",
            "sd only g_synthesis.blocks.64x64.conv0_up.intermediate.kernel torch.Size([1, 1, 3, 3])\n",
            "sd only g_synthesis.blocks.128x128.conv0_up.intermediate.kernel torch.Size([1, 1, 3, 3])\n",
            "sd only g_synthesis.blocks.256x256.conv0_up.intermediate.kernel torch.Size([1, 1, 3, 3])\n",
            "sd only g_synthesis.blocks.512x512.conv0_up.intermediate.kernel torch.Size([1, 1, 3, 3])\n",
            "sd only g_synthesis.blocks.1024x1024.conv0_up.intermediate.kernel torch.Size([1, 1, 3, 3])\n",
            "sd only 1024x1024.blur.kernel torch.Size([1, 1, 3, 3])\n",
            "sd only 1024x1024.conv1_down.downscale.blur.kernel torch.Size([1, 1, 2, 2])\n",
            "sd only 512x512.blur.kernel torch.Size([1, 1, 3, 3])\n",
            "sd only 512x512.conv1_down.downscale.blur.kernel torch.Size([1, 1, 2, 2])\n",
            "sd only 256x256.blur.kernel torch.Size([1, 1, 3, 3])\n",
            "sd only 256x256.conv1_down.downscale.blur.kernel torch.Size([1, 1, 2, 2])\n",
            "sd only 128x128.blur.kernel torch.Size([1, 1, 3, 3])\n",
            "sd only 128x128.conv1_down.downscale.blur.kernel torch.Size([1, 1, 2, 2])\n",
            "sd only 64x64.blur.kernel torch.Size([1, 1, 3, 3])\n",
            "sd only 64x64.conv1_down.downscale.blur.kernel torch.Size([1, 1, 2, 2])\n",
            "sd only 32x32.blur.kernel torch.Size([1, 1, 3, 3])\n",
            "sd only 32x32.conv1_down.downscale.blur.kernel torch.Size([1, 1, 2, 2])\n",
            "sd only 16x16.blur.kernel torch.Size([1, 1, 3, 3])\n",
            "sd only 16x16.conv1_down.downscale.blur.kernel torch.Size([1, 1, 2, 2])\n",
            "sd only 8x8.blur.kernel torch.Size([1, 1, 3, 3])\n",
            "sd only 8x8.conv1_down.downscale.blur.kernel torch.Size([1, 1, 2, 2])\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "wwUDCsPV4ioc"
      },
      "source": [
        "# Latent Vector Estimation"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "jftFL-yG4jIq"
      },
      "source": [
        "!mkdir save_image\n",
        "!mkdir save_image/encode1"
      ],
      "execution_count": 19,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "mwscGYEZ4usO",
        "outputId": "856ab959-bef1-4776-d79d-5c156f69c139"
      },
      "source": [
        "!python encode_image.py   --src_im sample.png --iteration 500"
      ],
      "execution_count": 20,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/torch/nn/functional.py:3458: UserWarning: Default upsampling behavior when mode=bilinear is changed to align_corners=False since 0.4.0. Please specify align_corners=True if the old behavior is desired. See the documentation of nn.Upsample for details.\n",
            "  \"See the documentation of nn.Upsample for details.\".format(mode)\n",
            "/usr/local/lib/python3.7/dist-packages/torch/nn/functional.py:3503: UserWarning: The default behavior for interpolate/upsample with float scale_factor changed in 1.6.0 to align with other frameworks/libraries, and now uses scale_factor directly, instead of relying on the computed output size. If you wish to restore the old behavior, please set recompute_scale_factor=True. See the documentation of nn.Upsample for details. \n",
            "  \"The default behavior for interpolate/upsample with float scale_factor changed \"\n",
            "Downloading: \"https://download.pytorch.org/models/vgg16-397923af.pth\" to /root/.cache/torch/hub/checkpoints/vgg16-397923af.pth\n",
            "100% 528M/528M [00:03<00:00, 168MB/s]\n",
            "Start\n",
            "iter0: loss -- 7.40569543838501,  mse_loss --0.061355095356702805,  percep_loss --7.3443403244018555\n",
            "iter10: loss -- 4.010244369506836,  mse_loss --0.05462613329291344,  percep_loss --3.955618381500244\n",
            "iter20: loss -- 3.512821674346924,  mse_loss --0.04428332298994064,  percep_loss --3.468538284301758\n",
            "iter30: loss -- 2.970721960067749,  mse_loss --0.019774887710809708,  percep_loss --2.9509470462799072\n",
            "iter40: loss -- 2.567082166671753,  mse_loss --0.014414042234420776,  percep_loss --2.5526680946350098\n",
            "iter50: loss -- 2.269507646560669,  mse_loss --0.013374609872698784,  percep_loss --2.2561330795288086\n",
            "iter60: loss -- 2.1275265216827393,  mse_loss --0.012626673094928265,  percep_loss --2.1148998737335205\n",
            "iter70: loss -- 2.1042885780334473,  mse_loss --0.012240462005138397,  percep_loss --2.092048168182373\n",
            "iter80: loss -- 2.021077871322632,  mse_loss --0.012390121817588806,  percep_loss --2.008687734603882\n",
            "iter90: loss -- 1.9262865781784058,  mse_loss --0.01187556516379118,  percep_loss --1.9144110679626465\n",
            "iter100: loss -- 1.861776351928711,  mse_loss --0.011890928260982037,  percep_loss --1.8498854637145996\n",
            "iter110: loss -- 1.8015214204788208,  mse_loss --0.011558359488844872,  percep_loss --1.7899630069732666\n",
            "iter120: loss -- 1.7348506450653076,  mse_loss --0.0113992840051651,  percep_loss --1.7234513759613037\n",
            "iter130: loss -- 1.7593462467193604,  mse_loss --0.01149747520685196,  percep_loss --1.7478487491607666\n",
            "iter140: loss -- 1.7122455835342407,  mse_loss --0.01103769801557064,  percep_loss --1.7012078762054443\n",
            "iter150: loss -- 1.6849970817565918,  mse_loss --0.010741508565843105,  percep_loss --1.674255609512329\n",
            "iter160: loss -- 1.667114496231079,  mse_loss --0.010779502801597118,  percep_loss --1.6563349962234497\n",
            "iter170: loss -- 1.646860957145691,  mse_loss --0.010828083381056786,  percep_loss --1.6360328197479248\n",
            "iter180: loss -- 1.628486156463623,  mse_loss --0.010296899825334549,  percep_loss --1.6181892156600952\n",
            "iter190: loss -- 1.612509846687317,  mse_loss --0.01074772235006094,  percep_loss --1.6017621755599976\n",
            "iter200: loss -- 1.573395848274231,  mse_loss --0.010345135815441608,  percep_loss --1.5630507469177246\n",
            "iter210: loss -- 1.6165739297866821,  mse_loss --0.010219469666481018,  percep_loss --1.6063544750213623\n",
            "iter220: loss -- 1.5357862710952759,  mse_loss --0.009753603488206863,  percep_loss --1.5260326862335205\n",
            "iter230: loss -- 1.471640944480896,  mse_loss --0.009547637775540352,  percep_loss --1.4620933532714844\n",
            "iter240: loss -- 1.4606304168701172,  mse_loss --0.00975849013775587,  percep_loss --1.4508719444274902\n",
            "iter250: loss -- 1.468252420425415,  mse_loss --0.009491704404354095,  percep_loss --1.4587607383728027\n",
            "iter260: loss -- 1.498616337776184,  mse_loss --0.009633226320147514,  percep_loss --1.488983154296875\n",
            "iter270: loss -- 1.479812502861023,  mse_loss --0.009497467428445816,  percep_loss --1.4703149795532227\n",
            "iter280: loss -- 1.4447993040084839,  mse_loss --0.009368862956762314,  percep_loss --1.4354304075241089\n",
            "iter290: loss -- 1.4364575147628784,  mse_loss --0.008985448628664017,  percep_loss --1.4274721145629883\n",
            "iter300: loss -- 1.4363600015640259,  mse_loss --0.009548356756567955,  percep_loss --1.426811695098877\n",
            "iter310: loss -- 1.3791085481643677,  mse_loss --0.008573105558753014,  percep_loss --1.3705354928970337\n",
            "iter320: loss -- 1.3954483270645142,  mse_loss --0.007985206320881844,  percep_loss --1.387463092803955\n",
            "iter330: loss -- 1.4253817796707153,  mse_loss --0.007997582666575909,  percep_loss --1.417384147644043\n",
            "iter340: loss -- 1.3538472652435303,  mse_loss --0.007938866503536701,  percep_loss --1.3459084033966064\n",
            "iter350: loss -- 1.4197461605072021,  mse_loss --0.008110418915748596,  percep_loss --1.4116357564926147\n",
            "iter360: loss -- 1.3597103357315063,  mse_loss --0.007785783614963293,  percep_loss --1.3519245386123657\n",
            "iter370: loss -- 1.3507206439971924,  mse_loss --0.007682835217565298,  percep_loss --1.3430378437042236\n",
            "iter380: loss -- 1.2948418855667114,  mse_loss --0.007683516945689917,  percep_loss --1.2871583700180054\n",
            "iter390: loss -- 1.2808257341384888,  mse_loss --0.007336793001741171,  percep_loss --1.273488998413086\n",
            "iter400: loss -- 1.287329077720642,  mse_loss --0.00714873056858778,  percep_loss --1.2801803350448608\n",
            "iter410: loss -- 1.3123282194137573,  mse_loss --0.007581881247460842,  percep_loss --1.304746389389038\n",
            "iter420: loss -- 1.2966469526290894,  mse_loss --0.0070849936455488205,  percep_loss --1.2895619869232178\n",
            "iter430: loss -- 1.336658000946045,  mse_loss --0.007030203007161617,  percep_loss --1.3296277523040771\n",
            "iter440: loss -- 1.2657132148742676,  mse_loss --0.007000611629337072,  percep_loss --1.258712649345398\n",
            "iter450: loss -- 1.2898015975952148,  mse_loss --0.006935185752809048,  percep_loss --1.282866358757019\n",
            "iter460: loss -- 1.2780811786651611,  mse_loss --0.00705643929541111,  percep_loss --1.2710247039794922\n",
            "iter470: loss -- 1.4212086200714111,  mse_loss --0.008266164921224117,  percep_loss --1.4129424095153809\n",
            "iter480: loss -- 1.5535482168197632,  mse_loss --0.008981133811175823,  percep_loss --1.5445671081542969\n",
            "iter490: loss -- 1.4058928489685059,  mse_loss --0.007472944911569357,  percep_loss --1.3984198570251465\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "XC5lRUHd5M_E"
      },
      "source": [
        "!mkdir morph_result\n",
        "!mkdir morph_result/encode1\n"
      ],
      "execution_count": 11,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "zM54evtm5O5m",
        "outputId": "1e8a8d8c-c114-4f48-ba87-c578d45c34fe"
      },
      "source": [
        "!python image_morphing.py --latent_file1 latent_W/0.npy --latent_file2 latent_W/sample.npy\n"
      ],
      "execution_count": 12,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "python3: can't open file 'image_morphing.py': [Errno 2] No such file or directory\n"
          ],
          "name": "stdout"
        }
      ]
    }
  ]
}